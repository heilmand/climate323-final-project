{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd60f92",
   "metadata": {},
   "source": [
    "### Helpful resources:\n",
    "* [Guide to Markdown](https://paperhive.org/help/markdown)\n",
    "* [Guide to LaTeX Math symbols](http://tug.ctan.org/info/undergradmath/undergradmath.pdf)\n",
    "* [Python Cheat Sheets](https://ehmatthes.github.io/pcc/cheatsheets/README.html)\n",
    "* [Moving to Python from MATLAB](https://bastibe.de/2013-01-20-a-python-primer-for-matlab-users.html)\n",
    "\n",
    "### Template for lab report:\n",
    "* **Title:** Name the lab that this report is for\n",
    "* **Collaborators:** Team work on labs is encouraged, but everyone is required to turn in their own lab report. Please list your collaborators in the intro to the report.\n",
    "* **Goal and Introduction:** Add a brief description of the goal and background knowledge for the lab. This can be drawn from the lab description, but should be in your own words.\n",
    "* **Data:** List the datasets used, what they describe and any quality/pre-processing before analysis.\n",
    "* **Approach and Results:** Describe your approach for each question in the lab description and interpretation of the results for that question.\n",
    "* **Conclusions:** Synthesize the conclusions from your results section here. Give overarching conclusions. Tell us what you learned.\n",
    "* **References:** Cite any resources or publications you used.\n",
    "---\n",
    "# Final Project\n",
    "### Elise Segal, Daniel Heilmen, Natalie Giovi, Percy Slattery\n",
    "\n",
    "## Goal and Introduction\n",
    "Add a brief description of the goal and background knowledge for the lab. This can be drawn from the lab description, but should be in your own words.\n",
    "\n",
    "## Data\n",
    "List the datasets used, what they describe and any quality/pre-processing before analysis.\n",
    "\n",
    "----\n",
    "## Approach and Results\n",
    "Describe your approach for each question in the lab description and interpretation of the results for that question.\n",
    "Start with an over-arching paragraph to describe your approach as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8466f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the libraries needed for the project\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "# time converter to datetime object for the OMNI data\n",
    "tconvert = lambda x: dt.datetime.strptime(str(x), '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "# reads the OMNI data into arrays\n",
    "data = np.genfromtxt('OMNI2_20002024.csv', names=True, delimiter=',', skip_header=97, encoding='utf-8',converters={0:tconvert}, dtype=None)\n",
    "\n",
    "time = data['TIME_AT_CENTER_OF_HOUR_yyyymmddThhmmsssssZ']\n",
    "swavgB = np.array(data['1AU_IP_MAG_AVG_B_nT'], dtype = float)\n",
    "swvelocity = np.array(data['1AU_IP_PLASMA_SPEED_Kms'], dtype = float)\n",
    "swpressure = np.array(data['1AU_IP_FLOW_PRESSURE_nPa'], dtype = float)\n",
    "swtemp = np.array(data ['1AU_IP_PLASMA_TEMP_Deg_K'], dtype = float)\n",
    "swdensity = np.array(data['1AU_IP_N_ION_Per_cc'], dtype = float)\n",
    "dst = np.array(data['1H_DST_nT'], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values that need to be filtered due to null data points\n",
    "arrays = [swavgB, swdensity, swvelocity, swpressure, swtemp]\n",
    "# maxs of the legitimate from OMNI\n",
    "filters = [99, 999, 9999, 99, 9999999]\n",
    "# filters out non data points to be null\n",
    "for array, threshold in zip(arrays, filters):\n",
    "    for index, value in enumerate(array):\n",
    "        if value >= threshold:\n",
    "            array[index] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlates data to labels\n",
    "data = {'Average Magnetic Field at 1 AU|Magnetic Field (nT)': (time,swavgB),\n",
    "        'Solar Wind Velocity|Velocity (km/s)': (time,swvelocity),\n",
    "        'Plasma Flow Pressure|Pressure (nPa)': (time,swpressure),\n",
    "        'Plasma Temperature|Temperature (K)': (time,swtemp),\n",
    "        'Ion Number Density|Density (per cc)': (time,swdensity),\n",
    "        'DST Index|DST (nT)': (time,dst)}\n",
    "fig, axes = plt.subplots(2,3, figsize = (15,8))\n",
    "# for loop to add data to each plot\n",
    "for ax, (label, (x, y)) in zip(axes.flat, data.items()):\n",
    "    #add data to the plot\n",
    "    ax.plot(x,y, color = '#bd1caa')\n",
    "    # adds proper titles and labels\n",
    "    title, space, ytext = label.partition('|')\n",
    "    ax.set_title(title)   \n",
    "    ax.set_xlabel(r'Date $(year)$')\n",
    "    ax.set_ylabel(ytext)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262acab5",
   "metadata": {},
   "source": [
    "Between 2019 and 2022 most of the data is consistent, showing low solar activity. The end of the data specifically around 2024 shows a lot of variety demostrating higher solar activy aligning with the solar cycle with solar min in 2019 and solar max in 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae9abd",
   "metadata": {},
   "source": [
    "While the most notable solar event from the plots is the May 2024 storm it is not the best example to show how solar wind parameters behave during a CME. This is because the May 2024 storm is the result of a cannibal CME which means that there were several CMEs that were back to back only a few hours apart. Therefore we decided to go with the April 23rd storm which was the result on a single CME to showcase how solar wind changes during a solar event. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb1002",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# creates a new figure for plots\n",
    "fig, axes = plt.subplots(2,3, figsize = (15,10))\n",
    "fig.suptitle('April 2023 CME')\n",
    "# for loop to add data to each plot\n",
    "for ax, (label, (x, y)) in zip(axes.flat, data.items()):\n",
    "    # add data to the plot\n",
    "    # narrows graph to just time around the 4/23/2023 CME\n",
    "    ax.set_xlim(dt.datetime(2023,4,22),dt.datetime(2023,4,27))\n",
    "    ax.plot(x,y, color = '#bd1caa')\n",
    "    # adds proper titles and labels\n",
    "    title, space, ytext = label.partition('|')\n",
    "    ax.set_title(title)   \n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel(ytext)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd634518",
   "metadata": {},
   "source": [
    "During a CME the magnetic field at 1 AU increases at the arrival of the CME and conitnues to increase before decreasing after the passing of the CME. The solar wind velocity also increases when the storm arrives before decreasing slightly again and remaining steady. There is a small peak in the solar wind pressure, density and temperature at the arrival of the CME before it decreases again. Lastly, the DST Index decreases to negative during the CME before recovering. This behavior matches the the structure of a CME. Typically a CME will have a shock associated with where the fast solar wind from the CME over takes the slow solar wind in front forming the shock. However, there does not have to be a shock associated with the CME. This causes an increase in solar wind speed when the shock and CME reach Lagrange point 1. Since the shock is at the beginning there is a bigger increase at the start of the CME before decreasing a little while the magnetic cloud of the CME passes. In the magnetic cloud of a CME there is a magnetic field as the name suggests. However the magnetic cloud mainly contains the magnetic cloud and nothing else. Therefore, the magnetic field should increase at the arrival of the shock and continue to increase and stay at a higher value during the passing of the magnetic cloud. However the solar wind parameter should increase at the arrival of the shock due to the compression of the solar wind but then drop during the passing of the magnetic cloud which is seen with the April 23rd storm of 2023. Lastly the DST measures the impact of the magnetic field on Earth surface with Earth's magnetic field therefore is showcases the opposite effect of Lagrange point 1 by decreasing due to the CME before recovering back to around 0 nT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a38e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft, ifft, fftfreq\n",
    "from scipy.signal import butter, filtfilt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper function: interpolate missing (NaN) values in the time series using linear interpolation\n",
    "def interpolate_nan(y):\n",
    "    nans = np.isnan(y)                          # Identify NaN positions\n",
    "    not_nans = ~nans                            # Identify valid (non-NaN) positions\n",
    "    x = np.arange(len(y))                       # Create an index array\n",
    "    y[nans] = np.interp(x[nans], x[not_nans], y[not_nans])  # Interpolate NaNs\n",
    "    return y\n",
    "\n",
    "def analyze_fft(data, dt_hours=1, top_k=6):\n",
    "    # Interpolate NaNs and prepare data\n",
    "    y = interpolate_nan(data.copy())\n",
    "    dt_days = dt_hours / 24\n",
    "    n = len(y)\n",
    "    \n",
    "    #gets ftt\n",
    "    data_fft = fft(y)/y.size # Normalize it\n",
    "    freqs = fftfreq(y.size, 1/24) # hours per day\n",
    "\n",
    "    power = np.abs(data_fft[1:y.size//2]**2) # Get that power\n",
    "    freq = freqs[1:y.size//2] # This is cycles-per-day.\n",
    "\n",
    "    # Filter to only positive frequencies\n",
    "    pos_mask = freq > 0\n",
    "    pos_freq = freq[pos_mask]\n",
    "    pos_power = power[pos_mask]\n",
    "    pos_indices = np.where(pos_mask)[0]\n",
    "\n",
    "    # Get top-k harmonics\n",
    "    harmonics = []\n",
    "    for _ in range(top_k):\n",
    "        idx_in_pos = np.argmax(pos_power)\n",
    "        global_idx = pos_indices[idx_in_pos]\n",
    "        harmonic = {\n",
    "            'amplitude': power[global_idx],\n",
    "            'frequency': freq[global_idx],\n",
    "            'period_days': 1 / freq[global_idx],\n",
    "            'harmonic_index': global_idx\n",
    "        }\n",
    "        harmonics.append(harmonic)\n",
    "        pos_power[idx_in_pos] = 0  # Remove this peak\n",
    "\n",
    "    return freq, power, n, harmonics\n",
    "\n",
    "def sort_harmonics_amp(harmonics):\n",
    "    sorted_h = sorted(harmonics, key=lambda h: h['amplitude'], reverse=True)\n",
    "    return sorted_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a166a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlates data with labels\n",
    "data = {'Average Magnetic Field at 1 AU|Magnetic Field (nT)': (time,swavgB),\n",
    "        'Solar Wind Velocity|Velocity (km/s)': (time,swvelocity),\n",
    "        'Plasma Flow Pressure|Pressure (nPa)': (time,swpressure),\n",
    "        'Plasma Temperature|Temperature (K)': (time,swtemp),\n",
    "        'Ion Number Density|Density (per cc)': (time,swdensity),\n",
    "        'DST Index|DST (nT)': (time,dst)}\n",
    "\n",
    "fig, axes = plt.subplots(2,3, figsize = (15,8))\n",
    "# for loop to add data to each plot\n",
    "fig.suptitle('Power Spectrums')\n",
    "\n",
    "dom_amps = []\n",
    "dom_freqs = []\n",
    "\n",
    "for ax, (label, (x, i)) in zip(axes.flat, data.items()):\n",
    "    freq, power, n, harmonics = analyze_fft(i)\n",
    "    sorted_amps = sort_harmonics_amp(harmonics)\n",
    "    #add data to the plot\n",
    "    ax.plot(freq[:n//2], power[:n//2], color = '#bd1caa')\n",
    "    # adds proper titles and labels\n",
    "    title, space, unit = label.partition('|')\n",
    "    ax.set_title(f'Power Spectrum of {title}')   \n",
    "    ax.set_xlabel(\"Frequency (cycles per day)\")\n",
    "    ax.set_ylabel(f\"Power ({unit}^2)\")\n",
    "    ax.set_xlim(-0.01,1.5)\n",
    "\n",
    "    freq = abs(freq)\n",
    "\n",
    "    dominant_frequencies = []\n",
    "\n",
    "    # Loop to find the top 5 dominant frequencies\n",
    "    for i in range(5):\n",
    "        # Find the index of the dominant frequency (maximum power) within the valid range\n",
    "        dominant_idx = np.argmax(power)\n",
    "        dom_amps.append(np.sqrt(power[dominant_idx]))\n",
    "        # Extract the dominant frequency in cycles/day\n",
    "        dominant_freq = freq[dominant_idx]\n",
    "        dom_freqs.append(dominant_freq)\n",
    "        # add to array\n",
    "        dominant_frequencies.append(dominant_freq)\n",
    "        # delete max power to find second dominant frequency\n",
    "        power = np.delete(power, dominant_idx)  \n",
    "\n",
    "    # Print the results\n",
    "    print(f'\\n{title}:')\n",
    "    for rank, freq in enumerate(dominant_frequencies, start=1):\n",
    "        days = 1 / freq\n",
    "        years = days / 365\n",
    "        print(f'\\t {rank} Dominant frequency: {freq:.4f} cycles per day (~{days:.2f} days or ~{years:.4f} years)')\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbeb0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data arrays\n",
    "arrays = [swavgB, swdensity, swvelocity, swpressure, swtemp, dst]\n",
    "# new arrays for the filtered data\n",
    "swavgB_filt = np.empty(swavgB.size)\n",
    "swdensity_filt = np.empty(swdensity.size)\n",
    "swvelocity_filt = np.empty(swvelocity.size)\n",
    "swpressure_filt = np.empty(swpressure.size)\n",
    "swtemp_filt = np.empty(swtemp.size)\n",
    "dst_filt = np.empty(dst.size)\n",
    "\n",
    "freq_ranged = 5/365\n",
    "freq_rangey = 62/365\n",
    "\n",
    "print(dom_freqs[0])\n",
    "print(dom_freqs[12])\n",
    "print(dom_freqs[13])\n",
    "\n",
    "newarray = [swavgB_filt, swdensity_filt, swvelocity_filt, swpressure_filt, swtemp_filt, dst_filt]\n",
    "# use ifft to filter out dominant frequencies found above\n",
    "for i in range(6):\n",
    "    x = interpolate_nan(arrays[i])\n",
    "    N = x.size\n",
    "    amps = fft(x)\n",
    "    freqs = fftfreq(N, 1/24)\n",
    "\n",
    "    mask1 = (np.abs(freqs) < dom_freqs[0]+freq_rangey) & (np.abs(freqs) > dom_freqs[0]-freq_rangey) & (freqs != 0)\n",
    "    mask2 = (np.abs(freqs) < dom_freqs[12]+freq_ranged) & (np.abs(freqs) > dom_freqs[12]-freq_ranged) & (freqs != 0)  \n",
    "    mask3 = (np.abs(freqs) < dom_freqs[13]+freq_ranged) & (np.abs(freqs) > dom_freqs[13]-freq_ranged) & (freqs != 0) \n",
    "\n",
    "    amps_filt = amps.copy()\n",
    "    amps_filt[mask1]=0\n",
    "    amps_filt[mask2]=0\n",
    "    amps_filt[mask3]=0\n",
    "    newarray[i] = ifft(amps_filt)\n",
    "\n",
    "swavgB_filt = newarray[0]\n",
    "swdensity_filt = newarray[1]\n",
    "swvelocity_filt = newarray[2]\n",
    "swpressure_filt = newarray[3]\n",
    "swtemp_filt = newarray[4]\n",
    "dst_filt = newarray[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affeb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlates data to labels\n",
    "data = {'Average Magnetic Field at 1 AU|Magnetic Field (nT)': (time,swavgB,swavgB_filt),\n",
    "        'Solar Wind Velocity|Velocity (km/s)': (time,swvelocity,swvelocity_filt),\n",
    "        'Plasma Flow Pressure|Pressure (nPa)': (time,swpressure,swpressure_filt),\n",
    "        'Plasma Temperature|Temperature (K)': (time,swtemp,swtemp_filt),\n",
    "        'Ion Number Density|Density (per cc)': (time,swdensity,swdensity_filt),\n",
    "        'DST Index|DST (nT)': (time,dst,dst_filt)}\n",
    "fig, axes = plt.subplots(2,3, figsize = (15,8))\n",
    "# for loop to add data to each plot\n",
    "for ax, (label, (x, y,filt)) in zip(axes.flat, data.items()):\n",
    "    #add data to the plot\n",
    "    ax.plot(x,y, label = 'Original Data', color = '#3477eb',alpha = 0.75)\n",
    "    ax.plot(x, filt, label = 'Filter Data', color = '#bd1caa', alpha = 0.75)\n",
    "    # adds proper titles and labels\n",
    "    title, space, ytext = label.partition('|')\n",
    "    ax.set_title(title)   \n",
    "    ax.set_xlabel(r'Date $(year)$')\n",
    "    ax.set_ylabel(ytext)\n",
    "    ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae78fe6",
   "metadata": {},
   "source": [
    "### Identifying DST Events 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c89ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import timedelta\n",
    "import math as math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#every hour\n",
    "dst_events = np.zeros(len(dst))\n",
    "for i in range(len(dst)):\n",
    "    if(dst[i] < -70):\n",
    "        dst_events[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e6b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we will create an array to hold our true/false values\n",
    "def calc_dst_binary(window_size, cutoff):\n",
    "    '''Creates a true or false array for whether or \n",
    "    not a dst event exists in each time interval\n",
    "    window is the window size in days\n",
    "    cutoff is the dst index below which we count an event, in units of nano-Teslas\n",
    "\n",
    "    Returns: binary event T/F array for dst data\n",
    "    '''\n",
    "    dst_binary = np.zeros(math.ceil(len(time) / (window_size * 24)))\n",
    "    window = timedelta(days=window_size)\n",
    "    start, stop = time[0], time[-1]\n",
    "    idx = 0\n",
    "    while start + window < stop:\n",
    "        end = start + window\n",
    "        locations = (time >= start) & (time < end)\n",
    "        subset = dst[locations]\n",
    "        if(np.min(subset) < cutoff):\n",
    "            dst_binary[idx] = True\n",
    "        start += window\n",
    "        idx += 1\n",
    "    return dst_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e8c63",
   "metadata": {},
   "source": [
    "### Identifying Events in the Filtered Solar Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce31934",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "swEvent = np.empty(swavgB_filt.size)\n",
    "\n",
    "for i in range(swavgB_filt.size):\n",
    "    c = 0\n",
    "    if swavgB_filt[i] > 15:\n",
    "        c = c+1\n",
    "    if swdensity_filt[i] > 15:\n",
    "        c = c+1\n",
    "    if swpressure_filt[i] > 10:\n",
    "        c = c+1\n",
    "    if swtemp_filt[i] > 7.5*10**5:\n",
    "        c = c+1\n",
    "    if swvelocity_filt[i] > 550:\n",
    "        c = c+1\n",
    "    if c >=3:\n",
    "        swEvent[i] = True\n",
    "    else:\n",
    "        swEvent[i] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80352bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will perform our binary event analysis on the Solar Wind data starting with the same cutoffs as chosen above\n",
    "#this time however, we will us a while loop and datetime objects to retrieve 5 day time intervals instead of\n",
    "#checking each data point individually\n",
    "#Here we will create an array to hold our true\n",
    "def calc_sw_binary(window, cutoffs):\n",
    "    '''Creates a true or false array for whether or \n",
    "    not a sw event exists in each time interval\n",
    "    window is the window size in days\n",
    "    cutoffs is an array that gives the cutoffs for each variable\n",
    "    [swavgB_filt, swdensity_filt, swpressure_filt, swtemp_filt, swvelocity_filt]\n",
    "\n",
    "    Returns: binary event T/F array for sw data\n",
    "    '''\n",
    "    sw_binary = np.zeros(math.ceil(len(time) / (window_size * 24)))\n",
    "    window = timedelta(days=window_size)\n",
    "    start, stop = time[0], time[-1]\n",
    "    idx = 0\n",
    "    count = 0\n",
    "    while start + window < stop:\n",
    "        end = start + window\n",
    "        locations = (time >= start) & (time < end)\n",
    "        subset = dst[locations]\n",
    "        c = 0\n",
    "        if np.max(swavgB_filt[locations]) > cutoffs[0]:\n",
    "            c = c+1\n",
    "        if np.max(swdensity_filt[locations]) > cutoffs[1]:\n",
    "            c = c+1\n",
    "        if np.max(swpressure_filt[locations]) > cutoffs[2]:\n",
    "            c = c+1\n",
    "        if np.max(swtemp_filt[locations]) > cutoffs[3]:\n",
    "            c = c+1\n",
    "        if np.max(swvelocity_filt[locations]) > cutoffs[4]:\n",
    "            c = c+1\n",
    "        if c >=3:\n",
    "            sw_binary[idx] = True\n",
    "        else:\n",
    "            sw_binary[idx] = False\n",
    "        start += window\n",
    "        idx += 1\n",
    "    return sw_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebce1f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the T/F array for events in the dst data\n",
    "window_size = 5 #days\n",
    "cutoff = -70 #nT\n",
    "dst_binary = calc_dst_binary(window_size, cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050914f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the T/F array for events in the sw data\n",
    "cutoffs = [15, 15, 10, 7.5*10**5, 550]\n",
    "sw_binary = calc_sw_binary(window_size, cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ceb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create figure and suplots to plot results\n",
    "fig, ([ax1, ax2], [ax3, ax4]) = plt.subplots(2,2, figsize=(10, 6))\n",
    "#dst events by hour\n",
    "ax1.plot(time, dst_events, color = '#bd1caa')\n",
    "#dst events 5 day window\n",
    "ax2.plot(dst_binary, color = '#bd1caa')\n",
    "#solar wind events by hour\n",
    "ax3.plot(time, swEvent, color = '#bd1caa')\n",
    "#solar wind events 5 day window\n",
    "ax4.plot(sw_binary, color = '#bd1caa')\n",
    "# adds proper titles and labels\n",
    "ax1.set_title('Events Identified from Hourly DST Data')   \n",
    "ax1.set_xlabel(r'Date $(year)$')\n",
    "ax1.set_ylabel('1 = Solar Event and 0 = No Event')\n",
    "\n",
    "ax2.set_title('Events Identified from DST Data, 5 day window')   \n",
    "ax2.set_xlabel('5 day window')\n",
    "ax2.set_ylabel('1 = Solar Event and 0 = No Event')\n",
    "\n",
    "ax3.set_title('Events Identified from Hourly Solar Wind Data')   \n",
    "ax3.set_xlabel(r'Date $(year)$')\n",
    "ax3.set_ylabel('1 = Solar Event and 0 = No Event')\n",
    "\n",
    "ax4.set_title('Events Identified from Solar Wind Data, 5 day window')   \n",
    "ax4.set_xlabel('5 day window')\n",
    "ax4.set_ylabel('1 = Solar Event and 0 = No Event')\n",
    "print(f'Total event idendified from solar wind data: {int(np.sum(swEvent))}')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25e3e0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "======="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea817e31",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "<<<<<<< HEAD\n",
    "=======\n",
    "### Question 1\n",
    "Write a function to read the *.csv files using numpy.genfromtxt. Leverage the example above to ensure success.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3\n",
    "Description of what you need to do and interpretation of results (if applicable)\n",
    "## here is binary event anaylsis on two lists that we can edit later --- just wanted to have something before wed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59618045",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "### Question 3\n",
    "#Description of what you need to do and interpretation of results (if applicable)\n",
    "## here is binary event anaylsis on two lists that we can edit later --- just wanted to have something before wed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "def binary_event_analysis(list1, list2):\n",
    "    \"\"\"\n",
    "    Analyzes two binary event lists.\n",
    "    \n",
    "    Parameters:\n",
    "    - list1, list2: Lists of binary values of equal length.\n",
    "    \n",
    "    This function computes:\n",
    "      - A contingency table for the two lists.\n",
    "      - The phi coefficient (correlation).\n",
    "      - The odds ratio.\n",
    "      - The hit rate, false alarm rate, proportion correct, and false alarm ratio.\n",
    "      - The Heidke Skill Score (HSS) for forecast skill.\n",
    "      - Chi-square test for independence.\n",
    "    \"\"\"\n",
    "    # Inputs are of equal length\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Both lists must have the same length.\")\n",
    "    \n",
    "    # Construct the contingency table elements\n",
    "    # a: True Positives, b: False Alarms, c: Misses, d: True Negatives.\n",
    "    a = sum(1 for i, j in zip(list1, list2) if i == 1 and j == 1)\n",
    "    b = sum(1 for i, j in zip(list1, list2) if i == 1 and j == 0)\n",
    "    c = sum(1 for i, j in zip(list1, list2) if i == 0 and j == 1)\n",
    "    d = sum(1 for i, j in zip(list1, list2) if i == 0 and j == 0)\n",
    "    \n",
    "    contingency_table = np.array([[a, b],\n",
    "                                  [c, d]])\n",
    "    \n",
    "    # Total number of observations\n",
    "    N = a + b + c + d\n",
    "    # Print contingency table\n",
    "    print(\"Contingency Table:\")\n",
    "    print(\"                list2=1   list2=0\")\n",
    "    print(f\"list1=1        {a:<9} {b}\")\n",
    "    print(f\"list1=0        {c:<9} {d}\\n\")\n",
    "    \n",
    "    # Compute phi coefficient\n",
    "    numerator = a * d - b * c\n",
    "    denominator = np.sqrt((a + b) * (c + d) * (a + c) * (b + d))\n",
    "    phi = numerator / denominator if denominator != 0 else np.nan\n",
    "    print(f\"Phi coefficient (correlation): {phi:.4f}\")\n",
    "    \n",
    "    # Calculate Odds Ratio\n",
    "    if b * c == 0:\n",
    "        odds_ratio = np.inf if a * d > 0 else np.nan\n",
    "        print(\"Odds Ratio: Division by zero occurred (one of b or c is 0); odds ratio set to infinity if numerator > 0.\")\n",
    "    else:\n",
    "        odds_ratio = (a * d) / (b * c)\n",
    "        print(f\"Odds Ratio: {odds_ratio:.4f}\")\n",
    "    \n",
    "    # Calculate additional performance metrics\n",
    "    # Hit Rate: Proportion of actual positive events (list2) that were correctly forecast\n",
    "    hit_rate = a / (a + c) if (a + c) != 0 else np.nan\n",
    "    # False Alarm Rate: Proportion of actual negative events (list2) that were falsely forecast as positive.\n",
    "    false_alarm_rate = b / (b + d) if (b + d) != 0 else np.nan\n",
    "    # Proportion Correct: Overall accuracy\n",
    "    proportion_correct = (a + d) / N if N != 0 else np.nan\n",
    "    # False Alarm Ratio: Proportion of forecasted positives that were false alarms\n",
    "    false_alarm_ratio = b / (a + b) if (a + b) != 0 else np.nan\n",
    "\n",
    "    Precision = (a) / (a + b) if (a) != 0 else np.nan\n",
    "    Recall = (a) / (a + c) if (a) != 0 else np.non\n",
    "    \n",
    "    print(f\"\\nHit Rate (True Positive Rate): {hit_rate:.4f}\")\n",
    "    print(f\"False Alarm Rate: {false_alarm_rate:.4f}\")\n",
    "    print(f\"Proportion Correct (Overall Accuracy): {proportion_correct:.4f}\")\n",
    "    print(f\"False Alarm Ratio: {false_alarm_ratio:.4f}\")\n",
    "    print(f\"Precision: {Precision}\")\n",
    "    print(f\"Recall: {Recall}\")\n",
    "\n",
    "    # Calculate Heidke Skill Score (HSS)\n",
    "    # Expected accuracy by chance\n",
    "    Pe = ((a + b) * (a + c) + (c + d) * (b + d)) / (N * N) if N != 0 else np.nan\n",
    "    # HSS: (observed accuracy - expected accuracy) / (1 - expected accuracy)\n",
    "    HSS = (proportion_correct - Pe) / (1 - Pe) if (1 - Pe) != 0 else np.nan\n",
    "    print(f\"Heidke Skill Score: {HSS:.4f}\")\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    plt.imshow(contingency_table, cmap=\"RdPu\", vmin=0, vmax=200)\n",
    "\n",
    "    #adding a colorbar to display the mapping of colors to numerical values.\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.title('Map of Confusion Matrix')\n",
    "    plt.xlabel('Observed Values')\n",
    "    plt.ylabel('Forecasted Values')\n",
    "\n",
    "    plt.xticks(ticks=[0, 1], labels=['1', '0'])\n",
    "    plt.yticks(ticks=[0, 1], labels=['1', '0'])\n",
    "\n",
    "    #get the numeric values\n",
    "    for i in range(contingency_table.shape[0]):\n",
    "        for j in range(contingency_table.shape[1]):\n",
    "            plt.text(j, i, str(contingency_table[i, j]),\n",
    "                     ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Return all results as a dictionary\n",
    "    return {\n",
    "        'contingency_table': contingency_table,\n",
    "        'phi_coefficient': phi,\n",
    "        'odds_ratio': odds_ratio,\n",
    "        'hit_rate': hit_rate,\n",
    "        'false_alarm_rate': false_alarm_rate,\n",
    "        'proportion_correct': proportion_correct,\n",
    "        'false_alarm_ratio': false_alarm_ratio,\n",
    "        'heidke_skill_score': HSS\n",
    "        'precision': precision \n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83014af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try out the binary analysis function, natalie please feel free to fix this part up and do it properly later!\n",
    "binary_event_analysis(dst_binary, sw_binary)\n",
    "print('\\n yay!  we have some stats! *high five*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d5ecd",
   "metadata": {},
   "source": [
    ">>>>>>> 1ae08bcd22831bb67a3e4a9b158ccb901410deab\n",
    "## Conclusions\n",
    "Synthesize the conclusions from your results section here. Give overarching conclusions. Tell us what you learned.\n",
    "## References\n",
    "List any references used\n",
    ">>>>>>> Stashed changes:test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3b3bc7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0201425",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d9d5b3b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "custom_cell_magics": "kql",
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
